{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765c0422",
   "metadata": {},
   "source": [
    "# 문제 6\n",
    "\n",
    "[Kaggle 형] train_prob.csv로 failure 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 failure가 1일 확률 예측하여 다음과 같은 형식의 answer6.csv를 만들어라. \n",
    "\n",
    "측정 지표는 AUC(area under of ROC curve)이다. id 는 테스트 케이스의 id 이고, failure에는 failure가 1이 될 확률이다.\n",
    "\n",
    "id,failure\n",
    "\n",
    "16115, 0.1\n",
    "\n",
    "16116, 0.2\n",
    "\n",
    "\n",
    "**강사: 멀티캠퍼스 강선구(sunku0316.kang@multicampus.com, sun9sun9@gmail.com)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ff1fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be131bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21458, 25), (5112, 24))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col='id')\n",
    "df_test = pd.read_csv('test_prob.csv', index_col='id')\n",
    "\n",
    "# 실제시험 x\n",
    "s_ans = pd.read_csv('test_prob_ans.csv', index_col=['id'])['failure']\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29dea4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['na_1'] = df_train['measurement_3'].isna()\n",
    "df_train['na_2'] = df_train['measurement_5'].isna()\n",
    "\n",
    "df_test['na_1'] = df_test['measurement_3'].isna()\n",
    "df_test['na_2'] = df_test['measurement_5'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "087871dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 1: train과 test의 product_code의 구성을 고려한 최적 방법\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import IterativeImputer # , random_state=123\n",
    "imp = IterativeImputer(\n",
    "    estimator=LinearRegression(fit_intercept=True), random_state=123\n",
    ")\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "df_train[X_imp] = df_train.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x), index=x.index, columns=X_imp)\n",
    ")\n",
    "df_test[X_imp] = df_test.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x), index=x.index, columns=X_imp)\n",
    ")\n",
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "df_train[X_mean] = df_train.groupby('product_code')[X_mean].transform(lambda x: x.fillna(x.mean()))\n",
    "df_test[X_mean] = df_test.groupby('product_code')[X_mean].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e6c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2 : train / test를 통합하여 처리해봅니다.\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer# 구문을 사용하여 실험 단계인 모듈을 활성화하고, \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "# train에 등장하지 않은 수준이 있습니다, test를 포함하여 결측처리 모델을 만듭니다.\n",
    "s_imp = pd.concat([\n",
    "        df_train[X_imp + ['product_code']],\n",
    "        df_test[X_imp + ['product_code']]\n",
    "], axis=0).groupby('product_code')\\\n",
    ".apply(\n",
    "    lambda x: IterativeImputer(estimator=LinearRegression(),random_state=123).fit(x[X_imp])\n",
    ")\n",
    "# train에 적용합니다.\n",
    "df_train[X_imp] = df_train[X_imp + ['product_code']]\\\n",
    "            .groupby('product_code')\\\n",
    "            .apply(\n",
    "                lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    "            )\n",
    "# test에 적용합니다.\n",
    "df_test[X_imp] = df_test[X_imp + ['product_code']]\\\n",
    "            .groupby('product_code')\\\n",
    "            .apply(\n",
    "                lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    "            )\n",
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "# train에 등장하지 않은 범주를 처리하기 위해 합치니다.\n",
    "df_mean = pd.concat([\n",
    "            df_train[['product_code'] + X_mean],\n",
    "            df_test[['product_code'] + X_mean]\n",
    "        ]).groupby('product_code')[X_mean].agg('mean')\n",
    "\n",
    "df_train[X_mean] = df_train.groupby('product_code')[X_mean]\\\n",
    "            .apply(lambda x: pd.DataFrame(x.fillna(df_mean.loc[x.name]), index=x.index, columns=x.columns))\n",
    "df_test[X_mean] = df_test.groupby('product_code')[X_mean]\\\n",
    "            .apply(lambda x: pd.DataFrame(x.fillna(df_mean.loc[x.name]), index=x.index, columns=x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f09d6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pd.concat([df_train['loading'], df_test['loading']]).mean()\n",
    "df_train['loading'] = df_train['loading'].fillna(m)\n",
    "df_test['loading'] = df_test['loading'].fillna(m)\n",
    "X_all = df_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b40b91da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum().pipe(\n",
    "    lambda x: x.loc[x > 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153384a4",
   "metadata": {},
   "source": [
    "## Step1: 검증 방법을 정하고, 검증 루틴을 만듭니다.\n",
    "\n",
    "Day1에서 했던 Holdout 검증보다 더 안정적인 평가 결과를 얻을 수 있는 교차 검증을 해봅니다.\n",
    "\n",
    "### GroupKFold에 대해 알아봅니다.\n",
    "\n",
    "Test의 product_code는 train에서 등장하지 않았습니다.\n",
    "\n",
    "이를 기반으로 검증 방법을 정해보면, \n",
    "\n",
    "product_code에 대해서 검증셋에서는 검증 학습셋에서 등장하지 않는 product_code가 되도록 구성을 하면, \n",
    "\n",
    "Test의 현상을 반영하는 검증 루틴을 구성할 수 있습니다.\n",
    "\n",
    "이에 활용할 수 있는 검증법이 바로 GroupKFold 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4d5504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'E'] ['C']\n",
      "['A' 'B' 'C'] ['E']\n",
      "['A' 'C' 'E'] ['B']\n",
      "['B' 'C' 'E'] ['A']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "gcv = GroupKFold(4)\n",
    "for train_idx, valid_idx in gcv.split(df_train[X_all], df_train['failure'], groups=df_train['product_code']):\n",
    "    df_cv_train, df_valid = df_train.iloc[train_idx], df_train.iloc[valid_idx]\n",
    "    print(df_cv_train['product_code'].unique(), df_valid['product_code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef679c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03427458, 0.03095746, 0.02125573, 0.03176475]),\n",
       " 'score_time': array([0.00419188, 0.01000667, 0.01005673, 0.00568748]),\n",
       " 'test_score': array([0.58821746, 0.58491734, 0.58894014, 0.59540058]),\n",
       " 'train_score': array([0.59262252, 0.59350804, 0.59192438, 0.58956303])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17'] ),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "cross_validate(\n",
    "    clf_lr, df_train[X_all], df_train['failure'], scoring='roc_auc', cv=gcv, groups = df_train['product_code'],\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ea63f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test 에서의 product_code가 등장하는 양상에 맞춰 검증 루틴을 구성해봅니다. (Step 1)\n",
    "s_hist = list()\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "gcv = GroupKFold(4)\n",
    "def eval_model(model_name, model):\n",
    "    \"\"\"\n",
    "        모델의 인스턴스를 받아 검증 결과(AUC) 를 구합니다.\n",
    "        1. GroupKFold 검증 - df_train, groups - product_code\n",
    "        2. df_valid에 대한 예측결과에 대한 AUC를 구합니다.\n",
    "        3. 주어진 모델명으로 평가 결과를 저장합니다. Format: Valid: {:.5f}±{:.5f}, Train: {:.5f}±{:.5f}\n",
    "        4. 가장 최근의 수행결과를 보여 주어 선택하는데 활용하도록 합니다.\n",
    "    Parameters:\n",
    "        model_name: str, 모델의 이름,\n",
    "        model: sklearn object, 모델 인스턴스\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "# 모델 선택 루틴입니다. (Step 3)\n",
    "def select_model(model):\n",
    "    \"\"\"\n",
    "        1. 전체 학습데이터(df_train)로 학습을 합니다. \n",
    "        2. df_test에 대한 예측을 합니다.\n",
    "        3. 예측 결과를 출력양식(id, failure)에 맞춰 csv파일을 만듭니다.\n",
    "        4. 자가 채점을 위한 예측 결과를 반환합니다.\n",
    "    Parameters: \n",
    "        model: sklearn object, 모델 인스턴스\n",
    "    Returns: 1차원 np.ndarray\n",
    "        예측 결과\n",
    "    \"\"\"\n",
    "    return np.zeros(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f77aae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3227a47b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
